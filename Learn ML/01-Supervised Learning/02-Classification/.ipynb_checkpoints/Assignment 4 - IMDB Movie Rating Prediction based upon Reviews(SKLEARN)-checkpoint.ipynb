{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB Movie Rating Prediction | NaiveBayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "The dataset for this problem is a subset of the IMDB movie review dataset (look at the IMDB movie review  dataset here - http://ai.stanford.edu/~amaas/data/sentiment/)). Given a movie review, task is to predict the rating given by the reviewer. Read the IMDB website for more details about the dataset. You have been provided with separate training and test files containing 25,000 reviews (samples) each. A review comes from one of the eight categories (class label). Here, class label represents rating given by the user along with the review.\n",
    "\n",
    "You are provided four files i) Train text ii) Train labels iii) Test text iv) Test labels. \n",
    "\n",
    "Text files contain one review in each line and label files contain the corresponding rating.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "(a) Implement the Naive Bayes algorithm to classify each of the articles into one of the given categories. Report the accuracy over the training as well as the test set. In the remaining parts below, we will only worry about test accuracy. Make sure to use the Laplace smoothing for Na¨ıve Bayes (as discussed) to avoid any zero probabilities. Use c = 1.\n",
    "```\n",
    "- **You should implement your algorithm using logarithms to avoid underflow issues.**\n",
    "- **You should implement Naive Bayes from the first principles and not use any existing Python Libraries. Use the Multinomial Event Model, write the code from scratch without using the steps given the in PDF.**\n",
    "\n",
    "(b) Accuracy\n",
    "- What is the test set accuracy that you would obtain by randomly guessing one of the categories as the target class for each of the articles (random prediction). What accuracy\n",
    "would you obtain if you simply predicted the class which occurs most of the times in the\n",
    "training data (majority prediction)? How much improvement does your algorithm give over the\n",
    "random/majority baseline?\n",
    "(c) Confusion matrix. Draw the confusion matrix for your results in the part (a) above (for the\n",
    "test data only). Which category has the highest value of the diagonal entry? What does that\n",
    "mean? What other observations can you draw from the confusion matrix? Include the confusion\n",
    "matrix in your submission and explain your observations.\n",
    "(d) Data Cleaning The dataset provided to is in the raw format i.e., it has all the words\n",
    "appearing in the original set of articles. This includes words such as ‘of’, ‘the’, ‘and’ etc. (called\n",
    "stopwords). Presumably, these words may not be relevant for classification. In fact, their\n",
    "presence can sometimes hurt the performance of the classifier by introducing noise in the data.\n",
    "Similarly, the raw data treats different forms of the same word separately, e.g., ‘eating’ and\n",
    "‘eat’ would be treated as separate words. Merging such variations into a single word is called\n",
    "stemming. • Read about stopword removal and stemming (for text classification) from videos\n",
    "shared\n",
    "Write one script to perform stemming and remove the stopwords in the training as well\n",
    "as the test data. Learn a new model on the transformed data. Again, report the\n",
    "accuracy.\n",
    "How does your accuracy change over test set? Comment on your observations.\n",
    "(e) Feature engineering is an essential component of Machine Learning. It refers to the\n",
    "process of manipulating existing features/constructing new features in order to help improve\n",
    "the overall accuracy on the prediction task. For example, instead of using each word as a\n",
    "feature, you may treat bi-grams (two consecutive words) as a feature. Come up with at least\n",
    "two alternative features and learn a new model based on those features. Add them on top of\n",
    "your model obtained in part (d) above. Compare with the test set accuracy that you obtained in\n",
    "parts (a) and parts (d). Which features help you improve the overall accuracy? Comment on\n",
    "your observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)-> help in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
