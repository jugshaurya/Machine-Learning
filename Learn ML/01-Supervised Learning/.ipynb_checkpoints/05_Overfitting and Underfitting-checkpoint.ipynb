{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting and Underfitting of Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[beautiful article on topic](https://towardsdatascience.com/overfitting-vs-underfitting-a-complete-example-d05dd7e19765)\n",
    "\n",
    "\n",
    "[good video by nptel for understanding](https://www.youtube.com/watch?v=Y0m136XU65o&list=PLyqSpQzTE6M9gCgajvQbc68Hk_JKGBAYT&index=58)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- underfitting the model means our complexity of function(degree) that we are predicting is very low compared to what it should be actually, when training our model\n",
    "\n",
    "- overfitting the model means our complexity of function that we are predicting is very high compared to what it should be actually(that is the error is very low over the training examples), when training our model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias \n",
    "    - difference b/w the actual value and predicted values\n",
    "# Variance \n",
    "- spreadness of the function from its average predicted function line if lines are drawn for various different training examples . \n",
    "- or `variance is an error from sensitivity to small fluctuations in the training set`\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Underfitting\n",
    "- assuming we have our training data,  as shown in fig using the simple function over my dataset in some chunks(15 maybe,consisting of 25 training examples each ).\n",
    "    - we are fitting lines over our model ,actual function is shown in black\n",
    "![](images/underfitting.PNG)\n",
    "\n",
    "- since our function was too simple , it results in higher difference b/w actual value and predicted value(higher bias).hence model is said to be underfitting the model.\n",
    "- note that its variance is low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting\n",
    "- assuming we have our training data,  as shown in fig using the complex function maybe polynomial of degree 25 over my dataset in some chunks(3 maybe,consisting of maybe 25 training examples each ).\n",
    "    - we are fitting function over our model , actual function is shown in black\n",
    "![](images/overfitting2.PNG)\n",
    "\n",
    "- since our function was too complex, it closely resembles the actual function (lower bias). \n",
    "- Hence model is said to be overfitting the model because it try to memorize the training data rather than learning from it.\n",
    "- note that its variance(values of same function for different training examples) is high here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-Variance Trade off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/trade-off.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/model.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
