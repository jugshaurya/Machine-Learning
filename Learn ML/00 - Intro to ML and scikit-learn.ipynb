{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An introduction to machine learning with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning: the problem setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- In general, a learning problem considers a set of `n samples` of data and then tries to predict properties of unknown data. If each sample is more than a single number and, for instance, a multi-dimensional entry (aka `multivariate data`), it is said to have several attributes or features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing scikit-learn\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Supervised Learning**,  in which the data comes with additional attributes that we want to predict .\n",
    "\n",
    "- **classification** : samples belong to two or more `classes` and we want to learn from already labeled data how to predict the class of unlabeled data.  classification is as a discrete (as opposed to continuous) form of supervised learning where one has a limited number of categories and for each of the n samples provided, one is to try to label them with the correct category or class.\n",
    "\n",
    "\n",
    "- **regression** : if the desired output consists of one or more continuous variables, then the task is called regression.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "   \n",
    "**UnSupervised Learning** , in which the training data consists of a set of input vectors x without any corresponding target values. \n",
    "    - The goal in such problems may be to discover groups of similar examples within the data, where it is called `clustering`, or to determine the distribution of data within the input space, known as `density estimation`, or to project the data from a high-dimensional space down to two or three dimensions for the purpose of visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  sklearn dataset Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# various datasets in datasets ,can `make` them ,can `load` them\n",
    "-  'load_boston',\n",
    "-  'load_breast_cancer',\n",
    "-  'load_diabetes',\n",
    "-  'load_digits',\n",
    "-  'load_files',\n",
    "-  'load_iris',\n",
    "-  'load_linnerud',\n",
    "-  'load_mlcomp',\n",
    "-  'load_sample_image',\n",
    "-  'load_sample_images',\n",
    "-  'load_svmlight_file',\n",
    "-  'load_svmlight_files',\n",
    "-  'load_wine',\n",
    "\n",
    "-  'make_biclusters',\n",
    "-  'make_blobs',\n",
    "-  'make_checkerboard',\n",
    "-  'make_circles',\n",
    "-  'make_classification',\n",
    "-  'make_moons',\n",
    "-  'make_regression',\n",
    " 'make_friedman1',\n",
    " 'make_friedman2',\n",
    " 'make_friedman3',\n",
    " 'make_gaussian_quantiles',\n",
    " 'make_hastie_10_2',\n",
    " 'make_low_rank_matrix',\n",
    " 'make_multilabel_classification',\n",
    " 'make_s_curve',\n",
    " 'make_sparse_coded_signal',\n",
    " 'make_sparse_spd_matrix',\n",
    " 'make_sparse_uncorrelated',\n",
    " 'make_spd_matrix',\n",
    " 'make_swiss_roll',\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For the best performance in the context of generalization, the complexity of the hypothesis should match the complexity of the function underlying the data. If the hypothesis is less complex than the function, then the model has underfit the data. If the complexity of the model is increased in response, then the training error decreases. But if the hypothesis is too complex, then the model is subject to overfitting and generalization will be poorer.\n",
    "\n",
    "\n",
    "\n",
    "- Supervised learning algorithms build a mathematical model of a set of data that contains both the inputs and the desired outputs.\n",
    "\n",
    "\n",
    "\n",
    "- The data is known as training data, and consists of a set of training examples. Each training example has one or more inputs and a desired output, also known as a supervisory signal. In the case of semi-supervised learning algorithms, some of the training examples are missing the desired output. In the mathematical model, each training example is represented by an array or vector, and the training data by a matrix. Through iterative optimization of an objective function, supervised learning algorithms learn a function that can be used to predict the output associated with new inputs.\n",
    "- An optimal function will allow the algorithm to correctly determine the output for inputs that were not a part of the training data. An algorithm that improves the accuracy of its outputs or predictions over time is said to have learned to perform that task.\n",
    "\n",
    "\n",
    "\n",
    "- Supervised learning algorithms include classification and regression.[20] Classification algorithms are used when the outputs are restricted to a limited set of values, and regression algorithms are used when the outputs may have any numerical value within a range. \n",
    "\n",
    "\n",
    "\n",
    "- In statistics, an estimator is a rule for calculating an estimate of a given quantity based on observed data: thus the rule (the estimator), the quantity of interest (the estimand) and its result (the estimate) are distinguished.[1]\n",
    "\n",
    "\n",
    "\n",
    "- In scikit-learn, an estimator for classification is a Python object that implements the methods fit(X, y) and predict(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
